{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84573c46",
   "metadata": {},
   "source": [
    "## Data Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139ba602",
   "metadata": {},
   "source": [
    "n-dimensional array aka tensor\n",
    "\n",
    "similar to ndarray from numpy with some killer features. \n",
    " - gpu suppoted to accelerate the coputation\n",
    " - tensor class supports automatic differentiation\n",
    " \n",
    " hence widely used for deep learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195defff",
   "metadata": {},
   "source": [
    " Level | Level for Humans | Level Description                  \n",
    " -------|------------------|------------------------------------ \n",
    "  0     | DEBUG            | [Default] Print all messages       \n",
    "  1     | INFO             | Filter out INFO messages           \n",
    "  2     | WARNING          | Filter out INFO & WARNING messages \n",
    "  3     | ERROR            | Filter out all messages      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8232e4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fce3e46",
   "metadata": {},
   "source": [
    "1 axis tensor = vector\n",
    "\n",
    "2 axis tensors = matrix\n",
    "\n",
    "3 or more axis = no mathematical name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "85bd194f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(12,), dtype=int32, numpy=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11], dtype=int32)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.range(12)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "26d7807f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([12])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7504f96",
   "metadata": {},
   "source": [
    "if we want total number of elements in the tensor, (multiplication of values in shape), use the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "72841f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=12>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.size(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "199c460c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 4])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.reshape(x, (3, 4))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fa5a28",
   "metadata": {},
   "source": [
    "dont have to mention all dimensions in reshape function. put -1 in one value, tf will automatically find out the rest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "88e8eccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 3])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.reshape(x, (-1, 3))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6db26c6",
   "metadata": {},
   "source": [
    "we can initialize with zero/constants/random samples from a distribution. \n",
    "\n",
    "can be done like below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7db6cac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros((2, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5ea7162b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4), dtype=float32, numpy=\n",
       "array([[[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]]], dtype=float32)>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.ones((2, 3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "833858f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[-0.67817247,  1.3990657 ,  0.4567462 ,  0.30003092],\n",
       "       [ 0.14387898,  1.0841188 ,  0.7172565 ,  2.1216674 ],\n",
       "       [-1.7713815 ,  0.20140563,  0.6365468 , -1.2981452 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.normal(shape = [3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58468644",
   "metadata": {},
   "source": [
    "we can also specify exact values using python lists or ndarrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7983949c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[1, 2, 3],\n",
       "       [4, 5, 6],\n",
       "       [7, 8, 9]], dtype=int32)>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e37aa38",
   "metadata": {},
   "source": [
    "### Operations on Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "76deb1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.range(5,10)\n",
    "y = tf.range(11,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b1b71f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(5,), dtype=int32, numpy=array([5, 6, 7, 8, 9], dtype=int32)>,\n",
       " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([11, 12, 13, 14, 15], dtype=int32)>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7871f7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(5,), dtype=int32, numpy=array([16, 18, 20, 22, 24], dtype=int32)>,\n",
       " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([-6, -6, -6, -6, -6], dtype=int32)>,\n",
       " <tf.Tensor: shape=(5,), dtype=int32, numpy=array([ 55,  72,  91, 112, 135], dtype=int32)>,\n",
       " <tf.Tensor: shape=(5,), dtype=float64, numpy=array([0.45454545, 0.5       , 0.53846154, 0.57142857, 0.6       ])>,\n",
       " <tf.Tensor: shape=(5,), dtype=int32, numpy=\n",
       " array([   48828125, -2118184960, -1895237401,           0, -1010140999],\n",
       "       dtype=int32)>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x+y, x-y, x*y, x/y, x**y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c2a072e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=244.69194>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.exp(5.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c54705",
   "metadata": {},
   "source": [
    "we can also concatenate multiple tensors to form a larger tensor. \n",
    "\n",
    "axis 0 -> first element of tf.shape\n",
    "\n",
    "axis 1 -> second element of tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "71334d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.reshape(tf.range(12, dtype = tf.float32), (3, 4))\n",
    "y = tf.reshape(tf.range(12, 24, dtype = tf.float32), (3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "653dd786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6, 4), dtype=float32, numpy=\n",
       "array([[ 0.,  1.,  2.,  3.],\n",
       "       [ 4.,  5.,  6.,  7.],\n",
       "       [ 8.,  9., 10., 11.],\n",
       "       [12., 13., 14., 15.],\n",
       "       [16., 17., 18., 19.],\n",
       "       [20., 21., 22., 23.]], dtype=float32)>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat([x, y], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a4f01ae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 8), dtype=float32, numpy=\n",
       "array([[ 0.,  1.,  2.,  3., 12., 13., 14., 15.],\n",
       "       [ 4.,  5.,  6.,  7., 16., 17., 18., 19.],\n",
       "       [ 8.,  9., 10., 11., 20., 21., 22., 23.]], dtype=float32)>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat([x, y], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b72d9a5",
   "metadata": {},
   "source": [
    "we can create binary tensors using comparision operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2b988dfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=bool, numpy=\n",
       "array([[False, False, False, False],\n",
       "       [False, False, False, False],\n",
       "       [False, False, False, False]])>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x == y "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5997a2",
   "metadata": {},
   "source": [
    "summing all elements in tensors yields tensor with only one element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "78314953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=66.0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db51c30",
   "metadata": {},
   "source": [
    "### Broadcasting Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb2041d",
   "metadata": {},
   "source": [
    "broadcasting : lets operations be performed on tensors of uneven size by expanding one or both tensors to a compatible shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3fc63aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1), dtype=int32, numpy=\n",
       "array([[0],\n",
       "       [1],\n",
       "       [2]], dtype=int32)>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.reshape(tf.range(3), (3, 1))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "95fd938a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=int32, numpy=array([[0, 1]], dtype=int32)>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = tf.reshape(tf.range(2), (1, 2))\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "bea4f6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[0, 1],\n",
       "       [1, 2],\n",
       "       [2, 3]], dtype=int32)>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb4ee8a",
   "metadata": {},
   "source": [
    "indexing is just like in normal python lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ebc0ab",
   "metadata": {},
   "source": [
    "### Saving Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769c0209",
   "metadata": {},
   "source": [
    "executing operations on tensors can sometimes cause the result to be hosted at a different memory locaiton. \n",
    "\n",
    "this is undesirable because we want to make optimal usage of memory and there might be hundreds of operations left. \n",
    "\n",
    "so we want to perform these operations _in place_ \n",
    "\n",
    "if this is not done, other references will still point to the old location leading to references to stale parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "16241e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139827493260176\n",
      "139827493260368\n",
      "139827493261136\n"
     ]
    }
   ],
   "source": [
    "x = tf.range(12)\n",
    "y = tf.range(13, 25)\n",
    "print(id(x))\n",
    "print(id(y))\n",
    "y = x + y\n",
    "print(id(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6dac21e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139827493077968\n",
      "139827493077968\n"
     ]
    }
   ],
   "source": [
    "z = tf.Variable(tf.zeros_like(y))\n",
    "print(id(z))\n",
    "z.assign(x + y)\n",
    "print(id(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284a7874",
   "metadata": {},
   "source": [
    "even when tf.Variable is used, it is better not to use it when not needed because, tensorflow tensors are immutable and gradients do not flow through variable assignments.\n",
    "\n",
    "but tensorflow provides tf.function decorator to wrap computation inside a tensorflow graph that gets compiled and optimized before running. \n",
    "\n",
    "this allows tf to prune unused values and reuse prior allocations and no longer needed. \n",
    "\n",
    "this minimizes the memory overhead of tensorflow computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b5e1da5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(12,), dtype=int32, numpy=\n",
       "array([ 52,  61,  70,  79,  88,  97, 106, 115, 124, 133, 142, 151],\n",
       "      dtype=int32)>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tf.function\n",
    "def computation(x, y):\n",
    "    z = tf.zeros_like(y)\n",
    "    a = x+y\n",
    "    b = a+y\n",
    "    c = b+y\n",
    "    return c+y\n",
    "\n",
    "computation(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5269fef1",
   "metadata": {},
   "source": [
    "when tensorflow arrays are converted to other datatypes (ndarrays for ex) they do not share memory. this detail needs more attention as it could lead to computation halts because the memory is being used by numpy when needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "106a5b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, tensorflow.python.framework.ops.EagerTensor)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = x.numpy()\n",
    "b = tf.constant(a)\n",
    "type(a), type(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf61827",
   "metadata": {},
   "source": [
    "to convert a size 1 tensor to a python scalar, we use item function or other python functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b8c6741f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.5], dtype=float32), 3.5, 3.5, 3)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([3.5]).numpy()\n",
    "a, a.item(), float(a), int(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e3f124",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63411f67",
   "metadata": {},
   "source": [
    "creating temp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d8aaad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs(os.path.join('..', 'data'), exist_ok=True)\n",
    "data_file = os.path.join('..', 'data', 'house_tiny.csv')\n",
    "with open(data_file, 'w') as f:\n",
    "    f.write('NumRooms,Alley,Price\\n')  # Column names\n",
    "    f.write('NA,Pave,127500\\n')  # Each row represents a data example\n",
    "    f.write('2,NA,106000\\n')\n",
    "    f.write('4,NA,178100\\n')\n",
    "    f.write('NA,NA,140000\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "70630520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms Alley   Price\n",
      "0       NaN  Pave  127500\n",
      "1       2.0   NaN  106000\n",
      "2       4.0   NaN  178100\n",
      "3       NaN   NaN  140000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(data_file)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c0d23fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms Alley\n",
      "0       3.0  Pave\n",
      "1       2.0   NaN\n",
      "2       4.0   NaN\n",
      "3       3.0   NaN\n"
     ]
    }
   ],
   "source": [
    "inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\n",
    "inputs['NumRooms'] = inputs['NumRooms'].fillna(inputs['NumRooms'].mean())\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d97352f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms  Alley_Pave  Alley_nan\n",
      "0       3.0           1          0\n",
      "1       2.0           0          1\n",
      "2       4.0           0          1\n",
      "3       3.0           0          1\n"
     ]
    }
   ],
   "source": [
    "inputs = pd.get_dummies(inputs, dummy_na=True)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3a61df60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4, 3), dtype=float64, numpy=\n",
       " array([[3., 1., 0.],\n",
       "        [2., 0., 1.],\n",
       "        [4., 0., 1.],\n",
       "        [3., 0., 1.]])>,\n",
       " <tf.Tensor: shape=(4,), dtype=int64, numpy=array([127500, 106000, 178100, 140000])>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = tf.constant(inputs.values), tf.constant(outputs.values)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159cb319",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ebbb1487",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms Alley\n",
      "0       3.0  Pave\n",
      "1       2.0   NaN\n",
      "2       4.0   NaN\n",
      "3       3.0   NaN\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(data_file)\n",
    "inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]\n",
    "inputs['NumRooms'] = inputs['NumRooms'].fillna(inputs['NumRooms'].mean())\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "83a9c8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = inputs.drop('Alley', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a5ed8ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 1), dtype=float64, numpy=\n",
       "array([[3.],\n",
       "       [2.],\n",
       "       [4.],\n",
       "       [3.]])>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.constant(inputs)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6343123b",
   "metadata": {},
   "source": [
    "## Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f42fad",
   "metadata": {},
   "source": [
    "x ∈ R means x in R\n",
    "\n",
    "scalar in tensorflow = tensor with just one element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e1972996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=8.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=-2.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=15.0>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.6>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=242.99998>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant(3.0)\n",
    "y = tf.constant(5.0)\n",
    "\n",
    "x+y, x-y, x*y, x/y, x**y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3995e624",
   "metadata": {},
   "source": [
    "vector = list of scalar values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3164092d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 1, 2, 3], dtype=int32)>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.range(4)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec719f18",
   "metadata": {},
   "source": [
    "if it's a normal list, we would use len(), but for tensors we use x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "28b0c652",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ba8e3d",
   "metadata": {},
   "source": [
    "generally, uppercase letters are used to denote matrices. \n",
    "\n",
    "mathematically, we represent them as: A∈Rm×n \n",
    "\n",
    "square matrix => m = n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0a52204a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 4), dtype=int32, numpy=\n",
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [12, 13, 14, 15],\n",
       "       [16, 17, 18, 19]], dtype=int32)>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = tf.reshape(tf.range(20), (5, 4))\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78436d8",
   "metadata": {},
   "source": [
    "tf.transpose(A) to calculate transpose of matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "9b5bc6fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 5), dtype=int32, numpy=\n",
       "array([[ 0,  4,  8, 12, 16],\n",
       "       [ 1,  5,  9, 13, 17],\n",
       "       [ 2,  6, 10, 14, 18],\n",
       "       [ 3,  7, 11, 15, 19]], dtype=int32)>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.transpose(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da4f7f0",
   "metadata": {},
   "source": [
    "just as vectors generalize scalars, matrices generalizes vectors, tensors are used to add more dimensions thus generalizing matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1866645d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5, 4), dtype=int32, numpy=\n",
       "array([[[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11],\n",
       "        [12, 13, 14, 15],\n",
       "        [16, 17, 18, 19]],\n",
       "\n",
       "       [[20, 21, 22, 23],\n",
       "        [24, 25, 26, 27],\n",
       "        [28, 29, 30, 31],\n",
       "        [32, 33, 34, 35],\n",
       "        [36, 37, 38, 39]]], dtype=int32)>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = tf.reshape(tf.range(40), (2,5,4))\n",
    "T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "587156f4",
   "metadata": {},
   "source": [
    "2 = number of tensors\n",
    "\n",
    "5 = number of rows in each matrix\n",
    "\n",
    "4 = number of columns in each matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6d654310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
       " array([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.],\n",
       "        [12., 13., 14., 15.],\n",
       "        [16., 17., 18., 19.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
       " array([[ 0.,  2.,  4.,  6.],\n",
       "        [ 8., 10., 12., 14.],\n",
       "        [16., 18., 20., 22.],\n",
       "        [24., 26., 28., 30.],\n",
       "        [32., 34., 36., 38.]], dtype=float32)>)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = tf.reshape(tf.range(20, dtype = tf.float32), (5, 4))\n",
    "B = A\n",
    "A, A+B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4043fdbb",
   "metadata": {},
   "source": [
    "no new memory is allocated to B above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5dc8f1f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139827492943248, 139827492943248)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id(A), id(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b8faaf",
   "metadata": {},
   "source": [
    "hadamard product = elementwise product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0f62c940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
       "array([[  0.,   1.,   4.,   9.],\n",
       "       [ 16.,  25.,  36.,  49.],\n",
       "       [ 64.,  81., 100., 121.],\n",
       "       [144., 169., 196., 225.],\n",
       "       [256., 289., 324., 361.]], dtype=float32)>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A * B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761ad015",
   "metadata": {},
   "source": [
    "tf.reduce_sum() to calculate sum of all elements of tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b58e96c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=4950>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = tf.reshape(tf.range(100), (2,5,10))\n",
    "tf.reduce_sum(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e48e6a6",
   "metadata": {},
   "source": [
    "we can also specify an axis along which it needs to be reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d3f46df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(5, 10), dtype=int32, numpy=\n",
       " array([[ 50,  52,  54,  56,  58,  60,  62,  64,  66,  68],\n",
       "        [ 70,  72,  74,  76,  78,  80,  82,  84,  86,  88],\n",
       "        [ 90,  92,  94,  96,  98, 100, 102, 104, 106, 108],\n",
       "        [110, 112, 114, 116, 118, 120, 122, 124, 126, 128],\n",
       "        [130, 132, 134, 136, 138, 140, 142, 144, 146, 148]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2, 10), dtype=int32, numpy=\n",
       " array([[100, 105, 110, 115, 120, 125, 130, 135, 140, 145],\n",
       "        [350, 355, 360, 365, 370, 375, 380, 385, 390, 395]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2, 5), dtype=int32, numpy=\n",
       " array([[ 45, 145, 245, 345, 445],\n",
       "        [545, 645, 745, 845, 945]], dtype=int32)>)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(A, axis = 0), tf.reduce_sum(A, axis = 1), tf.reduce_sum(A, axis = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dadab16",
   "metadata": {},
   "source": [
    "reducing a matrix along all axes is equivalent to sum of all elements aka reduce_sum without axis parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "517caa5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=4950>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(A, [0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9c5907c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5, 10), dtype=int32, numpy=\n",
       "array([[[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19],\n",
       "        [20, 21, 22, 23, 24, 25, 26, 27, 28, 29],\n",
       "        [30, 31, 32, 33, 34, 35, 36, 37, 38, 39],\n",
       "        [40, 41, 42, 43, 44, 45, 46, 47, 48, 49]],\n",
       "\n",
       "       [[50, 51, 52, 53, 54, 55, 56, 57, 58, 59],\n",
       "        [60, 61, 62, 63, 64, 65, 66, 67, 68, 69],\n",
       "        [70, 71, 72, 73, 74, 75, 76, 77, 78, 79],\n",
       "        [80, 81, 82, 83, 84, 85, 86, 87, 88, 89],\n",
       "        [90, 91, 92, 93, 94, 95, 96, 97, 98, 99]]], dtype=int32)>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "32c82012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1, 10), dtype=int32, numpy=\n",
       "array([[[100, 105, 110, 115, 120, 125, 130, 135, 140, 145]],\n",
       "\n",
       "       [[350, 355, 360, 365, 370, 375, 380, 385, 390, 395]]], dtype=int32)>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_a = tf.reduce_sum(A, axis = 1, keepdims = True)\n",
    "sum_a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142a9da3",
   "metadata": {},
   "source": [
    "we can calculate sum across an axis without reducing it's dimensions using cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "978d957a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5, 10), dtype=int32, numpy=\n",
       "array([[[  0,   1,   2,   3,   4,   5,   6,   7,   8,   9],\n",
       "        [ 10,  11,  12,  13,  14,  15,  16,  17,  18,  19],\n",
       "        [ 20,  21,  22,  23,  24,  25,  26,  27,  28,  29],\n",
       "        [ 30,  31,  32,  33,  34,  35,  36,  37,  38,  39],\n",
       "        [ 40,  41,  42,  43,  44,  45,  46,  47,  48,  49]],\n",
       "\n",
       "       [[ 50,  52,  54,  56,  58,  60,  62,  64,  66,  68],\n",
       "        [ 70,  72,  74,  76,  78,  80,  82,  84,  86,  88],\n",
       "        [ 90,  92,  94,  96,  98, 100, 102, 104, 106, 108],\n",
       "        [110, 112, 114, 116, 118, 120, 122, 124, 126, 128],\n",
       "        [130, 132, 134, 136, 138, 140, 142, 144, 146, 148]]], dtype=int32)>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cumsum(A, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7cfa39",
   "metadata": {},
   "source": [
    "the second tensor is sum of first and second tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8a2415",
   "metadata": {},
   "source": [
    "dot product = sum over products of elements in the same position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d6830d33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'Variable:0' shape=(4,) dtype=float32, numpy=array([0., 1., 2., 3.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(4,), dtype=float32, numpy=array([1., 1., 1., 1.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=6.0>)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable([0, 1, 2, 3], dtype = tf.float32)\n",
    "y = tf.ones(4, dtype = tf.float32)\n",
    "x, y, tf.tensordot(x, y, axes = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5951963d",
   "metadata": {},
   "source": [
    "it's equivalent to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f3fadd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=6.0>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(x * y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609e5178",
   "metadata": {},
   "source": [
    "matrix-vector product = Ax is a matrix vector product of length m whose i'th element is the dot product of aiTx\n",
    "\n",
    "this can be thought of as transformation of vector from Rn to Rm. \n",
    "\n",
    "tf.linalg.matvec(A, x) is the syntax. \n",
    "\n",
    "the height of A must be the same as length of x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ee557baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5, 4])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = tf.reshape(tf.range(20, dtype = tf.float32), (5,4))\n",
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9a855dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "940cc4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([ 14.,  38.,  62.,  86., 110.], dtype=float32)>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.linalg.matvec(A, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e940f8e",
   "metadata": {},
   "source": [
    "tf.matmul() to perform matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "cb89f476",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
       "array([[ 6.,  6.,  6.],\n",
       "       [22., 22., 22.],\n",
       "       [38., 38., 38.],\n",
       "       [54., 54., 54.],\n",
       "       [70., 70., 70.]], dtype=float32)>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = tf.ones((4,3), tf.float32)\n",
    "tf.matmul(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740bc405",
   "metadata": {},
   "source": [
    "norms intuitively tell us how big a vector is. big in terms of dimensionality rather than the magnitude of the components. \n",
    "\n",
    "in linear algebra, norm is a function that maps a vector to a scalar. \n",
    "\n",
    "l2 norm is square root of sum of squares of all elements. \n",
    "\n",
    "l2 is most common used norm in deep learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1e7b4f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=49.699093>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = tf.range(20, dtype = tf.float32)\n",
    "tf.norm(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "24834fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=49.699093>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tf.reshape(tf.range(20, dtype = tf.float32), (5,4))\n",
    "tf.norm(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4962b973",
   "metadata": {},
   "source": [
    "l1 norm is sum of absolute values of all elements. \n",
    "\n",
    "we can use tf.reduce_sum(tf.abs(u)) to calculate l1 norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21102b6",
   "metadata": {},
   "source": [
    "frobenius norm is square root of sum of squares of matrix elements. it is analogous to l2 norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8c22dc",
   "metadata": {},
   "source": [
    "why do we need norms?\n",
    "\n",
    "in deep learning we often try to solve optimization problems such as maximize probability assigned to observed data, minimize distance between predictions and ground truth observations. \n",
    "\n",
    "this optimizations are often expressed as norms. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd34b3ab",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e850fc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 4), dtype=bool, numpy=\n",
       "array([[ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True]])>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = tf.reshape(tf.range(20, dtype = tf.float32), (5, 4))\n",
    "A == tf.transpose(tf.transpose(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d4637d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 5), dtype=bool, numpy=\n",
       "array([[ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True],\n",
       "       [ True,  True,  True,  True,  True]])>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = tf.reshape(tf.range(20, 40, dtype = tf.float32), (5, 4))\n",
    "\n",
    "tf.transpose(A + B) == tf.transpose(A) + tf.transpose(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a08241d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[ 0.,  5., 10., 15.],\n",
       "       [ 5., 10., 15., 20.],\n",
       "       [10., 15., 20., 25.],\n",
       "       [15., 20., 25., 30.]], dtype=float32)>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = tf.reshape(tf.range(16, dtype = tf.float32), (4, 4))\n",
    "C + tf.transpose(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2d1f9f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.reshape(tf.range(40), (2,5,4))\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5ab237b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=409.2432>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = tf.reshape(tf.range(80, dtype = tf.float32), (2,2,5,4))\n",
    "tf.linalg.norm(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f78f7e",
   "metadata": {},
   "source": [
    "## Calculus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a9c558",
   "metadata": {},
   "source": [
    "method of exhaustion = in the old days, people did not know how to calculate areas of circles. so what they did was they inscribe polygons inside the circles, calculated the  areas of those polygons to approximate the area of the circle. \n",
    "\n",
    "this is where integral calculus got it's origin. \n",
    "\n",
    "\n",
    "almost 2000 years later, differential calculus was invented. optimization problems is one of the best applications of differential calculus. \n",
    "\n",
    "in deep learning, we train models, updating them successively until the results get better. \n",
    "\n",
    "usually getting better means minimizing a loss function. loss function's result is basically a score that tells how bad is the model. \n",
    "\n",
    "this task of fitting models is decomposed into two tasks. \n",
    "\n",
    "1. optimization: fitting our models to observed data. \n",
    "\n",
    "2. generalization: producing models that extend beyond the data samples on which the model is trained on. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e01e2e0",
   "metadata": {},
   "source": [
    "in deep learning, we typically choose loss functions that are differentiable. this is so that we can determine how rapidly the loss would increase or decrease if we were to increase or decrease that parameter by an infinitesimally small amount. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "73df1336",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 3 * x ** 2 - 4 * x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2a8f8a",
   "metadata": {},
   "source": [
    "## Automatic Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e008b2",
   "metadata": {},
   "source": [
    "deep learning frameworks expedite the process of differentiation by automatically calculating the derivatives aka automatic differentiation. \n",
    "\n",
    "based on the model, the system builds a computational graph which tracks the operations performed on the data to get the output. \n",
    "\n",
    "automatic differentiation enables system to subsequently backpropogate gradients. backpropogate = filling in the partial deriatives wrt each parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "c060f531",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.range(4, dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc066eb",
   "metadata": {},
   "source": [
    "it is important that we do not allocate new memory every time derivative is taken because we often update the same parameteres thousands of times and we could quickly run out of memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d8c1e0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(4,) dtype=float32, numpy=array([0., 1., 2., 3.], dtype=float32)>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.Variable(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bacad57",
   "metadata": {},
   "source": [
    "assume y = 2 * xT * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "69ac6e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=28.0>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tf.GradientTape() as t:\n",
    "    y = 2 * tf.tensordot(x, x, axes = 1)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6fd9a338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([ 0.,  4.,  8., 12.], dtype=float32)>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_grad = t.gradient(y, x)\n",
    "x_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110d46a8",
   "metadata": {},
   "source": [
    "y = 2xTx,\n",
    "\n",
    "it's derivative is 4x. let's verify that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "3f3542fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=bool, numpy=array([ True,  True,  True,  True])>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_grad == 4*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e01dd68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=6.0>,\n",
       " <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0., 2., 4., 6.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=14.0>)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc = tf.range(4, dtype= tf.float32)\n",
    "tf.reduce_sum(abc), 2 * abc, tf.reduce_sum(abc * abc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202d186f",
   "metadata": {},
   "source": [
    "detaching computation:\n",
    "\n",
    "say y is calculated as a function of x and z is calculated as a function of y. sometimes we want to calculate the gradient of z with respect to x but for some reason do it while treating y as a constant and only take into account the role x played in calculating z. \n",
    "\n",
    "this can be done using tf.stop_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6ee27211",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.GradientTape(persistent = True) as t:\n",
    "    y = x * x\n",
    "    u = tf.stop_gradient(y)\n",
    "    z = u * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ccd6b318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=bool, numpy=array([ True,  True,  True,  True])>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_grad = t.gradient(z, x)\n",
    "x_grad == u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "2679f52f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=bool, numpy=array([ True,  True,  True,  True])>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.gradient(y, x) == 2 * x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d420e4c",
   "metadata": {},
   "source": [
    "gradients can also be calculated for python control flow statements like conditionals, loops and function calls. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "ec243aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a):\n",
    "    b = a * 2\n",
    "    while tf.norm(b) < 1000:\n",
    "        b = b * 2\n",
    "    if tf.reduce_sum(b) > 0:\n",
    "        c = b\n",
    "    else:\n",
    "        c = 100 * b\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5116813d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=204800.0>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.Variable(tf.random.normal(shape = ()))\n",
    "with tf.GradientTape() as t:\n",
    "    d = f(a)\n",
    "\n",
    "d_grad = t.gradient(d, a)\n",
    "d_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5705c3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(a):\n",
    "    b = a * 2\n",
    "    while tf.norm(b) < 1000:\n",
    "        b = b * 2\n",
    "    if tf.reduce_sum(b) > 0:\n",
    "        c = b\n",
    "    else:\n",
    "        c = 100 * b\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7f767f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=204800.0>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.Variable(tf.random.normal(shape=()))\n",
    "with tf.GradientTape() as t:\n",
    "    d = f(a)\n",
    "d_grad = t.gradient(d, a)\n",
    "d_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d97c6cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=False>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_grad == d/a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6dba3ae",
   "metadata": {},
   "source": [
    "## Probability "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b4d00c",
   "metadata": {},
   "source": [
    "machine learning in some ways is all about making predictions. \n",
    "\n",
    "we need to think predict the probability of an event happening or how likely a reading is about to happen etc.,\n",
    "\n",
    "refer to github.com/asrjy/ai-notes for detailed notes on probability of machine learning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c454cdff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
