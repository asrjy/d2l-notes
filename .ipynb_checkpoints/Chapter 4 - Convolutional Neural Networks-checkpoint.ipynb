{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "734f8090",
   "metadata": {},
   "source": [
    "## From Fully-Connected Layers to Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad5c8c6",
   "metadata": {},
   "source": [
    "in other nn models, we anticipate patterns we seek could involve interactions among features but we do not assume any structure concerning how these features interact. \n",
    "\n",
    "if we do not know how to create crafty architectures to solve such issues, an mlp may just be the best thing one could do. but for high dimensional data, such mlps can grow unweildy. \n",
    "\n",
    "for example, a neural network model that classfies dogs and cats pictures that are of size 1 mega pixel i.e., 1000000 dimensions, and a fully connected neural network of size 1000, would mean 1 billion parameters. even with a lot of patience and very well performing GPUs, it's infeasible. \n",
    "\n",
    "one might argue that we may not need a 1mp image. even if we reduce the quality down to 100000, it's still infeasible with billions of parameters. and fitting lots of parameters require collecting an enormous dataset. yet, humans are easily able to distinguish between them. this is because the images exhibit rich structure that can be exploited by humans and machine learning models alike. CNNs are one creative way to exploit the structure in such images. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fc1d17",
   "metadata": {},
   "source": [
    "#### Invariance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0403255",
   "metadata": {},
   "source": [
    "spatial invariance: the model's ability to identify targets regardless of it's position in the image. for example the model should be able to identify pigs in the sky and planes on the ground. \n",
    "\n",
    "translation invariance: in the early layers of our network, the model should respond similarly to a patch regardless of it's position in the image. \n",
    "\n",
    "locality principle: in the early layers of our network, the network should focus on local regions regardless of the contents of the image in other distant regions. eventually, these local representations can be aggregated to make predictions at the whole image level. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c039c86d",
   "metadata": {},
   "source": [
    "#### Constraining the MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003c9ad7",
   "metadata": {},
   "source": [
    "let X be a two dimensional image which is the input to the network and their hidden representations as H. they both have the same shape which is a two dimensional tensor. we assume that both the image and hidden representations possess spatial structure. \n",
    "\n",
    "![hidden cell equation](./images/7/7.1.png \"Hidden Layer Equation\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e42df21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
